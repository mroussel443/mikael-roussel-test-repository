{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../DAT-NYC-9-27/projects/unit-projects/project-2/assets/admissions.csv')\n",
    "admissions_data = raw_data.dropna()\n",
    "print admissions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables relative to whether someone got admitted or not. Think in terms of for a certain prestige level, how many people got admitted and didnt get admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1145eb210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEe5JREFUeJzt3XuMZnV9x/H3Z3cRWFGKtewYERZsBTStQCloqfFRIHiJ\nQhOKWi+A0Vhrgy2JcSFWxj/aQNLWUtsmWi9ZvLQiysWKATbLmNgGlioo5bLVWPG6o60XCqJc9ts/\nnrPLMDvzzJkdznMZ36/kyZ5znnOe851fZp/P/M7ld1JVSJK0ZtQFSJLGg4EgSQIMBElSw0CQJAEG\ngiSpYSBIkoAhBEKSA5N8KsldSe5IcmKSg5Jcn2R7kuuSHNh1HZKkwYbRQ7gUuLaqjgaeC9wNbAK2\nVNWRwFbggiHUIUkaIF3emJbkycCtVfXMecvvBl5YVbNJpoCZqjqqs0IkSUvquodwOPA/ST6S5MtJ\nPpBkPbChqmYBqmoHcHDHdUiSltB1IKwDjgP+oaqOA+6nf7hofrfE8TMkacTWdfz53wG+XVX/0cx/\nmn4gzCbZMOeQ0Q8W2jiJQSFJe6GqstxtOu0hNIeFvp3kWc2ik4E7gGuAc5plZwNXD/iMiX1ddNFF\nI6/hl7X+Sa7d+kf/mvT691bXPQSA84CPJ9kH+AZwLrAWuDzJG4F7gLOGUIckaYDOA6GqvgL8zgJv\nndL1viVJ7Xmncod6vd6oS1iRSa5/kmsH6x+1Sa9/b3V6H8JKJalxrk+SxlESatxOKkuSJoeBIEkC\nDARJUsNAkCQBBoIkqWEgSJIAA0GS1DAQJEmAgSBJahgIkiTAQJAkNQwESRJgIEiSGgaCJAkwECRJ\nDQNBkgQYCJKkhoEgSQIMBElSw0CQJAEGgibQ1NRGkgz1NTW1cdQ/ttS5VNWoa1hUkhrn+jQaSYBh\n/14Efxc1KZJQVVnudvYQJEmAgSBJahgIkiTAQJAkNdZ1vYMk3wR+CuwEHqqqE5IcBHwSOAz4JnBW\nVf2061okSYsbRg9hJ9CrqmOr6oRm2SZgS1UdCWwFLhhCHZKkAYYRCFlgP6cDm5vpzcAZQ6hDkjTA\nMAKhgBuS3JLkTc2yDVU1C1BVO4CDh1CHJGmAzs8hACdV1feT/BpwfZLt7HlXkXf8SNKIdR4IVfX9\n5t8fJrkKOAGYTbKhqmaTTAE/WGz76enp3dO9Xo9er9dtwZI0YWZmZpiZmVnx53Q6dEWS9cCaqrov\nyROB64H3ACcDP6qqS5K8EzioqjYtsL1DV2gPDl0hDba3Q1d0HQiHA1fS/9+7Dvh4VV2c5CnA5cAz\ngHvoX3b6kwW2NxC0BwNBGmwsA2GlDAQtxECQBnNwO0nSihgIkiTAQJAkNQwESRJgIEiSGgaCJAkw\nECRJDQNBkgQYCJKkhoEgSQIMBElSw0CQJAEGgiSpYSBIkgADQZLUMBAkSYCBIElqGAiSJMBAkCQ1\nDARJEmAgSJIaBoIkCTAQJEkNA0GSBBgIkqSGgSBJAgwESVLDQJAkAQaCJKkxlEBIsibJl5Nc08wf\nlOT6JNuTXJfkwGHUIUla3LB6CG8H7pwzvwnYUlVHAluBC4ZUhyRpEZ0HQpJDgJcBH5yz+HRgczO9\nGTij6zokSYMNo4fwXuAdQM1ZtqGqZgGqagdw8BDqkCQNsK7LD0/ycmC2qm5L0huwai32xvT09O7p\nXq9HrzfoYyTpl8/MzAwzMzMr/pxULfpdvPIPT/4SeB3wMLA/8CTgSuB4oFdVs0mmgBur6ugFtq8u\n69NkSsKAvyG62iv+LmpSJKGqstztOj1kVFUXVtWhVXUE8Gpga1W9HvgscE6z2tnA1V3WIUla2qju\nQ7gYODXJduDkZl6SNEKdHjJaKQ8ZaSEeMpIGG8tDRpKkyWEgSJIAA0GS1DAQJEmAgSBJahgIkiTA\nQJAkNQwESRLQMhCS/GbXhUiSRqttD+Efk2xL8sc+3UySVqdWgVBVLwBeCzwD+FKSTyQ5tdPKJElD\ntayxjJKspf90s78D7gUCXFhVn+mkOMcy0gIcy0garNOxjJL8VpL3AncBLwZe0Ty/4MX0n4gmSZpw\nrXoISb5A/5nIV1TVA/Pee31VfbST4uwhaAH2EKTB9raH0DYQDgAeqKpHmvk1wH5V9bNlV7qc4gwE\nLcBAkAbrevjrLfQfgbnL+maZJGmVaBsI+1XVfbtmmun13ZQkSRqFtoFwf5Ljds0k+W3ggQHrS5Im\nzLqW6/0p8Kkk36N/qekU8KrOqpIkDV3r+xCS7AMc2cxur6qHOqvq0X16Ull78KSyNFinVxk1O/hd\nYCNzehVVddlyd7gckxwI27ZtY2ZmZqj7POKIIzjzzDOHus9RMBCkwbq+7PSjwDOB24BHmsVVVect\nd4fLMcmB8LznncYttzyZNWsOH9IeH6HqfTz88IND2t/oGAjSYHsbCG3PIRwPPHtiv51HoAp27nwT\nO3eeNqQ9Psjate8b0r4krUZtrzL6T/onkiVJq1TbHsJTgTuTbAN+sWthVb2yk6okSUPXNhCmuyxC\nkjR6rQKhqr6Q5DDgN6pqS5L1wNpuS5MkDVPb4a/fDFwBvL9Z9HTgqq6KkiQNX9uTym8DTqL/UByq\n6mvAwUttlGTfJDcnuTXJ7UkuapYflOT6JNuTXOdjOSVp9NoGwi+qavcF7knW0eJC8Kr6BfCiqjoW\nOAZ4aZITgE3Alqo6EtgKXLDsyiVJj6u2gfCFJBcC+zfPUv4U8Nk2G855ZsK+9M9ZFHA6sLlZvpn+\nYzklSSPUNhA2AT8EbgfeAlwLvKvNhknWJLkV2AHcUFW3ABuqahagqnbQ4vCTJKlbba8y2gn8U/Na\nlmbbY5M8GbgyyXPY83DTooefpqend0/3ej16vd5yS5CkVW1mZuZxGTut7VhG/80CX9pVdcSydpb8\nOfAz4E1Ar6pmk0wBN1bV0QusP7GjZZx44mls23Y+MMyhKw5wLKPu9upYRpoYwxjLaJf9gD8AntKi\nqKcCD1XVT5PsD5wKXAxcA5wDXAKcDVy9jJolSR1oe8jof+ct+tskXwLevcSmTwM2J1lD/3zFJ6vq\n2iQ3AZcneSNwD3DWMuuWJD3OWgXC3Mdn0v9iP77NtlV1O3DcAst/BJzSskZJ0hC0PWT013OmHwa+\niX/VS9Kq0vaQ0Yu6LkSSNFptDxmdP+j9qvqbx6ccSdKotL0x7XjgrfQHtXs68Ef0zw08qXlJmnBT\nUxtJMtTX1NTGUf/YmqPtOYRDgOOq6v8AkkwDn6uq13VVmKThmp29h2Hf3zE7u+xL5dWhtj2EDcDc\nO54ebJZJklaJtj2Ey4BtSa5s5s/g0cHpJEmrQNurjP4iyeeBFzSLzq2qW7srS5I0bG0PGQGsB+6t\nqkuB7yQ5vKOaJEkj0PYRmhcB7+TRB9nsA3ysq6IkScPXtofw+8ArgfsBqup7eLmpJK0qbQPhwWYc\n6gJI8sTuSpIkjULbQLg8yfuBX0nyZmALe/GwHEnS+Gp7ldFfNc9Svhc4Enh3Vd3QaWWSpKFaMhCS\nrAW2NAPcGQKStEotecioqh4BdiY5cAj1SJJGpO2dyvcBtye5geZKI4CqOq+TqiRJQ9c2ED7TvCRJ\nq9TAQEhyaFV9q6oct0iSVrmlziFctWsiyac7rkWSNEJLBcLcwcqP6LIQSdJoLRUItci0JGmVWeqk\n8nOT3Eu/p7B/M00zX1X15E6rkyQNzcBAqKq1wypEkjRay3kegiRpFTMQJEmAgSBJahgIkiSg40BI\nckiSrUnuSHJ7kvOa5QcluT7J9iTXOXCeJI1e1z2Eh4Hzq+o5wPOBtyU5CthEf0jtI4GtPPqsZknS\niHQaCFW1o6pua6bvA+4CDgFOB3aNj7QZOKPLOiRJSxvaOYQkG4FjgJuADVU1C/3QAA4eVh2SpIW1\nHf56RZIcAFwBvL2q7ksyfxiMRYfFmJ6e3j3d6/Xo9XpdlChJE2tmZoaZmZkVf06quh2iKMk64F+B\nz1fVpc2yu4BeVc0mmQJurKqjF9i2uq6vKyeeeBrbtp0PnDakPT7I2rUH8PDDDw5pf6OThOEPrRUm\n9XexLdt19UhCVWXpNR9rGIeMPgzcuSsMGtcA5zTTZwNXD6EOSdIAnR4ySnIS8Fr6j9+8lf6fHxcC\nlwCXJ3kjcA9wVpd1SJKW1mkgVNW/AYsNkHdKl/uWJC2PdypLkgADQZLUMBAkSYCBIElqGAiSJMBA\nkCQ1DARJEmAgSJIaBoIkCTAQJEkNA0GSBBgIkqSGgSBJAgwESVLDQJAkAQaCJKlhIEiSAANBktQw\nECRJgIEgSWoYCJIkwECQJDUMBEkSYCBIkhoGgiQJgHWjLkCSVrOpqY3Mzt4z6jJaMRAkqUP9MKgh\n7zV7tZWHjCRJQMeBkORDSWaTfHXOsoOSXJ9ke5LrkhzYZQ2SpHa67iF8BDht3rJNwJaqOhLYClzQ\ncQ2SpBY6DYSq+iLw43mLTwc2N9ObgTO6rEGS1M4oziEcXFWzAFW1Azh4BDVIkuYZh5PKwz79Lkla\nwCguO51NsqGqZpNMAT8YtPL09PTu6V6vR6/X67Y6SZo4M81rZYYRCOGxF8VeA5wDXAKcDVw9aOO5\ngSBJWkivee3ynr36lK4vO/0E8O/As5J8K8m5wMXAqUm2Ayc385KkEeu0h1BVf7jIW6d0uV9J0vKN\nw0llSdIYMBAkSYCBIElqGAiSJMBAkCQ1DARJEmAgSJIaBoIkCTAQJEkNA0GSBBgIkqSGgSBJAgwE\nSVLDQJAkAQaCJKlhIEiSAANBktQwECRJgIEgSWoYCJIkwECQJDUMBEkSYCBIkhoGgiQJMBAkSQ0D\nQZIEGAiSpIaBIEkCRhgISV6S5O4k/5XknaOqQ5LUN5JASLIG+HvgNOA5wGuSHDWKWrr1lVEXsCIz\nMzOjLmEFZkZdwIpMdtuD7T+ZRtVDOAH4WlXdU1UPAf8CnD6iWjr01VEXsCKT/Z9iZtQFrMhktz3Y\n/pNpVIHwdODbc+a/0yyTJI3IulEXsFrtt98+rFt3I+vXv2JIe9zJz3++z5D2JWk1SlUNf6fJ84Dp\nqnpJM78JqKq6ZN56wy9OklaBqspytxlVIKwFtgMnA98HtgGvqaq7hl6MJAkY0SGjqnokyZ8A19M/\nj/Ehw0CSRmskPQRJ0vgZizuVl7pJLckLk/wkyZeb17tGUedCknwoyWySRa8xTfJ3Sb6W5LYkxwyz\nvqUsVf+Yt/0hSbYmuSPJ7UnOW2S9sWz/NvWPefvvm+TmJLc29V+0yHrj2v5L1j/O7Q/9e7qauq5Z\n5P3ltX1VjfRFP5S+DhwG7APcBhw1b50XAteMutZF6v894Bjgq4u8/1Lgc830icBNo655mfWPc9tP\nAcc00wfQPy81/3dnbNu/Zf1j2/5Nfeubf9cCNwEnTEr7t6x/3Nv/z4CPLVTj3rT9OPQQ2t6ktuwz\n5sNQVV8EfjxgldOBy5p1bwYOTLJhGLW10aJ+GN+231FVtzXT9wF3sef9LGPb/i3rhzFtf4Cq+lkz\nuS/9c5Lzj0GPbftDq/phTNs/ySHAy4APLrLKstt+HAKh7U1qz2+6PZ9L8uzhlPa4mP/zfZfJuwlv\n7Ns+yUb6PZ2b5701Ee0/oH4Y4/ZvDlncCuwAbqiqW+atMtbt36J+GN/2fy/wDhYOMdiLth+HQGjj\nS8ChVXUM/TGQrhpxPb9Mxr7tkxwAXAG8vflLe6IsUf9Yt39V7ayqY4FDgBPH7AtzSS3qH8v2T/Jy\nYLbpYYbHqRczDoHwXeDQOfOHNMt2q6r7dnXtqurzwD5JnjK8Elfku8Az5szv8fONs3Fv+yTr6H+Z\nfrSqrl5glbFu/6XqH/f236Wq7gVuBF4y762xbv9dFqt/jNv/JOCVSb4B/DPwoiSXzVtn2W0/DoFw\nC/DrSQ5L8gTg1cBjzpjPPe6V5AT6l8v+aLhlDjQooa8B3gC779D+SVXNDquwlhatfwLa/sPAnVV1\n6SLvj3v7D6x/nNs/yVOTHNhM7w+cCtw9b7Wxbf829Y9r+1fVhVV1aFUdQf87c2tVvWHeastu+5GP\nZVSL3KSW5C39t+sDwJlJ3go8BDwAvGp0FT9Wkk8APeBXk3wLuAh4Ak3tVXVtkpcl+TpwP3Du6Krd\n01L1M95tfxLwWuD25jhwARfSv2Jt7Nu/Tf2McfsDTwM2pz+c/Rrgk0177/6/O87tT4v6Ge/238NK\n294b0yRJwHgcMpIkjQEDQZIEGAiSpIaBIEkCDARJUsNAkCQBBoIkqWEgSJIA+H/dFb+DQoWbaQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1145eb990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "admit_only = admissions_data[admissions_data.admit == 1]\n",
    "admit_only.describe()\n",
    "admit_only.plot(x='admit',y='prestige',kind='hist',legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    53\n",
       "1.0    33\n",
       "3.0    28\n",
       "4.0    12\n",
       "Name: prestige, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admit_only.prestige.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1.0  2.0  3.0  4.0\n",
      "0    0.0  0.0  1.0  0.0\n",
      "1    0.0  0.0  1.0  0.0\n",
      "2    1.0  0.0  0.0  0.0\n",
      "3    0.0  0.0  0.0  1.0\n",
      "4    0.0  0.0  0.0  1.0\n",
      "5    0.0  1.0  0.0  0.0\n",
      "6    1.0  0.0  0.0  0.0\n",
      "7    0.0  1.0  0.0  0.0\n",
      "8    0.0  0.0  1.0  0.0\n",
      "9    0.0  1.0  0.0  0.0\n",
      "10   0.0  0.0  0.0  1.0\n",
      "11   1.0  0.0  0.0  0.0\n",
      "12   1.0  0.0  0.0  0.0\n",
      "13   0.0  1.0  0.0  0.0\n",
      "14   1.0  0.0  0.0  0.0\n",
      "15   0.0  0.0  1.0  0.0\n",
      "16   0.0  0.0  0.0  1.0\n",
      "17   0.0  0.0  1.0  0.0\n",
      "18   0.0  1.0  0.0  0.0\n",
      "19   1.0  0.0  0.0  0.0\n",
      "20   0.0  0.0  1.0  0.0\n",
      "21   0.0  1.0  0.0  0.0\n",
      "22   0.0  0.0  0.0  1.0\n",
      "23   0.0  0.0  0.0  1.0\n",
      "24   0.0  1.0  0.0  0.0\n",
      "25   1.0  0.0  0.0  0.0\n",
      "26   1.0  0.0  0.0  0.0\n",
      "27   0.0  0.0  0.0  1.0\n",
      "28   0.0  1.0  0.0  0.0\n",
      "29   1.0  0.0  0.0  0.0\n",
      "..   ...  ...  ...  ...\n",
      "370  0.0  1.0  0.0  0.0\n",
      "371  0.0  0.0  1.0  0.0\n",
      "372  1.0  0.0  0.0  0.0\n",
      "373  1.0  0.0  0.0  0.0\n",
      "374  0.0  1.0  0.0  0.0\n",
      "375  0.0  0.0  0.0  1.0\n",
      "376  0.0  1.0  0.0  0.0\n",
      "377  0.0  1.0  0.0  0.0\n",
      "378  0.0  0.0  1.0  0.0\n",
      "379  0.0  1.0  0.0  0.0\n",
      "380  0.0  1.0  0.0  0.0\n",
      "381  0.0  1.0  0.0  0.0\n",
      "382  0.0  1.0  0.0  0.0\n",
      "383  1.0  0.0  0.0  0.0\n",
      "384  0.0  1.0  0.0  0.0\n",
      "385  1.0  0.0  0.0  0.0\n",
      "386  0.0  1.0  0.0  0.0\n",
      "387  0.0  1.0  0.0  0.0\n",
      "388  0.0  1.0  0.0  0.0\n",
      "389  0.0  1.0  0.0  0.0\n",
      "390  0.0  1.0  0.0  0.0\n",
      "391  0.0  1.0  0.0  0.0\n",
      "392  0.0  0.0  1.0  0.0\n",
      "393  0.0  1.0  0.0  0.0\n",
      "394  0.0  0.0  1.0  0.0\n",
      "395  0.0  1.0  0.0  0.0\n",
      "396  0.0  0.0  1.0  0.0\n",
      "397  0.0  1.0  0.0  0.0\n",
      "398  0.0  1.0  0.0  0.0\n",
      "399  0.0  0.0  1.0  0.0\n",
      "\n",
      "[397 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "prestige_dummies = pd.get_dummies(admissions_data.prestige)\n",
    "print prestige_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For the prestige class variables we need 3 out of the 4 in order to avoid the problem of multicollinearity. In this case we will remove class 4 because it is the least significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  1.0  2.0  3.0  4.0\n",
      "0      0  380.0  3.61  0.0  0.0  1.0  0.0\n",
      "1      1  660.0  3.67  0.0  0.0  1.0  0.0\n",
      "2      1  800.0  4.00  1.0  0.0  0.0  0.0\n",
      "3      1  640.0  3.19  0.0  0.0  0.0  1.0\n",
      "4      0  520.0  2.93  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = admissions_data[cols_to_keep].join(prestige_dummies.ix[:, 1:4])\n",
    "print handCalc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#crosstab prestige 1 admission \n",
    "# frequency table cutting prestige and whether or not someone was admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    148\n",
       "3.0    121\n",
       "4.0     67\n",
       "1.0     61\n",
       "Name: prestige, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_data.prestige.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prestige_1 = admissions_data[admissions_data.prestige == 1]\n",
    "prestige_1.admit.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5409836065573771"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of admit for prestige level 1 applicants\n",
    "33./61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_prestige_1 = admissions_data[admissions_data.prestige != 1]\n",
    "non_prestige_1.admit.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2767857142857143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of admit for prestige non level 1 applicants\n",
    "93./336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1785714285714288"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Odds of being admitted if attended a #1 ranked school\n",
    "0.5409836065573771/(1-0.5409836065573771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The odds are 1.18/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3827160493827161"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2767857142857143/(1-0.2767857142857143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The odds are .38/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1052631578947367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.18/.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of being admitted if one went to a level 1 prestige school is about 3 times higher than if one did not go to a level 1 prestige school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.80182622]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression()\n",
    "model = lm.fit(handCalc[[ 6]], handCalc['admit'])\n",
    "print lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44850914]]\n"
     ]
    }
   ],
   "source": [
    "print np.exp(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:As expected, the odds ratio for prestige level 4 schools is the lowest of all the prestige levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  2.0  3.0  4.0\n",
      "0      0  380.0  3.61  0.0  1.0  0.0\n",
      "1      1  660.0  3.67  0.0  1.0  0.0\n",
      "2      1  800.0  4.00  0.0  0.0  0.0\n",
      "3      1  640.0  3.19  0.0  0.0  1.0\n",
      "4      0  520.0  2.93  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = admissions_data[cols_to_keep].join(prestige_dummies.ix[:, 2:])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  2.0  3.0  4.0  intercept\n",
       "0  380.0  3.61  0.0  1.0  0.0        1.0\n",
       "1  660.0  3.67  0.0  1.0  0.0        1.0\n",
       "2  800.0  4.00  0.0  0.0  0.0        1.0\n",
       "3  640.0  3.19  0.0  0.0  1.0        1.0\n",
       "4  520.0  2.93  0.0  0.0  1.0        1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "model = lm.fit(train_cols,data['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00188666  0.32452811 -0.6200671  -1.16988125 -1.3847737  -1.09518905]]\n",
      "[-1.09518905]\n"
     ]
    }
   ],
   "source": [
    "print lm.coef_\n",
    "print lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00188844  1.38337769  0.53790834  0.3104038   0.25038045  0.33447637]]\n"
     ]
    }
   ],
   "source": [
    "#Below are the odds rations for the different coefficients\n",
    "print np.exp(lm.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The OR of Prestige_2 is 0.54. This means that the odds of getting admitted if one went to a tier 2 school decreases by 46%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of being admitted increases by 38% for every 1 unit increase in GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    3\n",
       "0  220.0  2.260000  1.0  1.0\n",
       "1  220.0  2.260000  2.0  1.0\n",
       "2  220.0  2.260000  3.0  1.0\n",
       "3  220.0  2.260000  4.0  1.0\n",
       "4  220.0  2.453333  1.0  1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combos.columns=[\"gre\",\"gpa\",\"prestige\",\"One\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>One</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa  prestige  One\n",
       "0  220.0  2.260000       1.0  1.0\n",
       "1  220.0  2.260000       2.0  1.0\n",
       "2  220.0  2.260000       3.0  1.0\n",
       "3  220.0  2.260000       4.0  1.0\n",
       "4  220.0  2.453333       1.0  1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recreate the dummy variables\n",
    "\n",
    "# keep only what we need for making predictions\n",
    "\n",
    "dummies=pd.get_dummies(combos['prestige'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa\n",
       "0  220.0  2.260000\n",
       "1  220.0  2.260000\n",
       "2  220.0  2.260000\n",
       "3  220.0  2.260000\n",
       "4  220.0  2.453333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_gpa=combos[['gre','gpa']]\n",
    "gre_gpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa  2.0  3.0  4.0\n",
       "0  220.0  2.260000  0.0  0.0  0.0\n",
       "1  220.0  2.260000  1.0  0.0  0.0\n",
       "2  220.0  2.260000  0.0  1.0  0.0\n",
       "3  220.0  2.260000  0.0  0.0  1.0\n",
       "4  220.0  2.453333  0.0  0.0  0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combos_new = gre_gpa.join(dummies)\n",
    "combos_new= combos_new[['gre','gpa',2,3,4]]\n",
    "combos_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One=combos[['One']]\n",
    "type (One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>One</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>220.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>800.0</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>800.0</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gre       gpa  2.0  3.0  4.0  One\n",
       "0    220.0  2.260000  0.0  0.0  0.0  1.0\n",
       "1    220.0  2.260000  1.0  0.0  0.0  1.0\n",
       "2    220.0  2.260000  0.0  1.0  0.0  1.0\n",
       "3    220.0  2.260000  0.0  0.0  1.0  1.0\n",
       "4    220.0  2.453333  0.0  0.0  0.0  1.0\n",
       "5    220.0  2.453333  1.0  0.0  0.0  1.0\n",
       "6    220.0  2.453333  0.0  1.0  0.0  1.0\n",
       "7    220.0  2.453333  0.0  0.0  1.0  1.0\n",
       "8    220.0  2.646667  0.0  0.0  0.0  1.0\n",
       "9    220.0  2.646667  1.0  0.0  0.0  1.0\n",
       "10   220.0  2.646667  0.0  1.0  0.0  1.0\n",
       "11   220.0  2.646667  0.0  0.0  1.0  1.0\n",
       "12   220.0  2.840000  0.0  0.0  0.0  1.0\n",
       "13   220.0  2.840000  1.0  0.0  0.0  1.0\n",
       "14   220.0  2.840000  0.0  1.0  0.0  1.0\n",
       "15   220.0  2.840000  0.0  0.0  1.0  1.0\n",
       "16   220.0  3.033333  0.0  0.0  0.0  1.0\n",
       "17   220.0  3.033333  1.0  0.0  0.0  1.0\n",
       "18   220.0  3.033333  0.0  1.0  0.0  1.0\n",
       "19   220.0  3.033333  0.0  0.0  1.0  1.0\n",
       "20   220.0  3.226667  0.0  0.0  0.0  1.0\n",
       "21   220.0  3.226667  1.0  0.0  0.0  1.0\n",
       "22   220.0  3.226667  0.0  1.0  0.0  1.0\n",
       "23   220.0  3.226667  0.0  0.0  1.0  1.0\n",
       "24   220.0  3.420000  0.0  0.0  0.0  1.0\n",
       "25   220.0  3.420000  1.0  0.0  0.0  1.0\n",
       "26   220.0  3.420000  0.0  1.0  0.0  1.0\n",
       "27   220.0  3.420000  0.0  0.0  1.0  1.0\n",
       "28   220.0  3.613333  0.0  0.0  0.0  1.0\n",
       "29   220.0  3.613333  1.0  0.0  0.0  1.0\n",
       "..     ...       ...  ...  ...  ...  ...\n",
       "370  800.0  2.646667  0.0  1.0  0.0  1.0\n",
       "371  800.0  2.646667  0.0  0.0  1.0  1.0\n",
       "372  800.0  2.840000  0.0  0.0  0.0  1.0\n",
       "373  800.0  2.840000  1.0  0.0  0.0  1.0\n",
       "374  800.0  2.840000  0.0  1.0  0.0  1.0\n",
       "375  800.0  2.840000  0.0  0.0  1.0  1.0\n",
       "376  800.0  3.033333  0.0  0.0  0.0  1.0\n",
       "377  800.0  3.033333  1.0  0.0  0.0  1.0\n",
       "378  800.0  3.033333  0.0  1.0  0.0  1.0\n",
       "379  800.0  3.033333  0.0  0.0  1.0  1.0\n",
       "380  800.0  3.226667  0.0  0.0  0.0  1.0\n",
       "381  800.0  3.226667  1.0  0.0  0.0  1.0\n",
       "382  800.0  3.226667  0.0  1.0  0.0  1.0\n",
       "383  800.0  3.226667  0.0  0.0  1.0  1.0\n",
       "384  800.0  3.420000  0.0  0.0  0.0  1.0\n",
       "385  800.0  3.420000  1.0  0.0  0.0  1.0\n",
       "386  800.0  3.420000  0.0  1.0  0.0  1.0\n",
       "387  800.0  3.420000  0.0  0.0  1.0  1.0\n",
       "388  800.0  3.613333  0.0  0.0  0.0  1.0\n",
       "389  800.0  3.613333  1.0  0.0  0.0  1.0\n",
       "390  800.0  3.613333  0.0  1.0  0.0  1.0\n",
       "391  800.0  3.613333  0.0  0.0  1.0  1.0\n",
       "392  800.0  3.806667  0.0  0.0  0.0  1.0\n",
       "393  800.0  3.806667  1.0  0.0  0.0  1.0\n",
       "394  800.0  3.806667  0.0  1.0  0.0  1.0\n",
       "395  800.0  3.806667  0.0  0.0  1.0  1.0\n",
       "396  800.0  4.000000  0.0  0.0  0.0  1.0\n",
       "397  800.0  4.000000  1.0  0.0  0.0  1.0\n",
       "398  800.0  4.000000  0.0  1.0  0.0  1.0\n",
       "399  800.0  4.000000  0.0  0.0  1.0  1.0\n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos_more_new=combos_new.join(One)\n",
    "combos_more_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73921249  0.26078751]\n",
      " [ 0.84049914  0.15950086]\n",
      " [ 0.90130067  0.09869933]\n",
      " [ 0.91883729  0.08116271]\n",
      " [ 0.72693702  0.27306298]\n",
      " [ 0.83190717  0.16809283]\n",
      " [ 0.89557704  0.10442296]\n",
      " [ 0.91403362  0.08596638]\n",
      " [ 0.71430705  0.28569295]\n",
      " [ 0.82294987  0.17705013]\n",
      " [ 0.88956216  0.11043784]\n",
      " [ 0.90897381  0.09102619]\n",
      " [ 0.70133292  0.29866708]\n",
      " [ 0.81362219  0.18637781]\n",
      " [ 0.88324598  0.11675402]\n",
      " [ 0.90364758  0.09635242]\n",
      " [ 0.68802692  0.31197308]\n",
      " [ 0.80392018  0.19607982]\n",
      " [ 0.87661867  0.12338133]\n",
      " [ 0.89804465  0.10195535]\n",
      " [ 0.67440334  0.32559666]\n",
      " [ 0.7938411   0.2061589 ]\n",
      " [ 0.86967069  0.13032931]\n",
      " [ 0.89215479  0.10784521]\n",
      " [ 0.6604784   0.3395216 ]\n",
      " [ 0.78338352  0.21661648]\n",
      " [ 0.86239286  0.13760714]\n",
      " [ 0.88596788  0.11403212]\n",
      " [ 0.6462703   0.3537297 ]\n",
      " [ 0.77254746  0.22745254]\n",
      " [ 0.85477649  0.14522351]\n",
      " [ 0.879474    0.120526  ]\n",
      " [ 0.63179908  0.36820092]\n",
      " [ 0.76133449  0.23866551]\n",
      " [ 0.84681344  0.15318656]\n",
      " [ 0.87266345  0.12733655]\n",
      " [ 0.61708661  0.38291339]\n",
      " [ 0.7497478   0.2502522 ]\n",
      " [ 0.83849626  0.16150374]\n",
      " [ 0.8655269   0.1344731 ]\n",
      " [ 0.71510216  0.28489784]\n",
      " [ 0.82351732  0.17648268]\n",
      " [ 0.88994467  0.11005533]\n",
      " [ 0.90929594  0.09070406]\n",
      " [ 0.70214908  0.29785092]\n",
      " [ 0.81421279  0.18578721]\n",
      " [ 0.88364751  0.11635249]\n",
      " [ 0.90398656  0.09601344]\n",
      " [ 0.68886332  0.31113668]\n",
      " [ 0.80453414  0.19546586]\n",
      " [ 0.87703982  0.12296018]\n",
      " [ 0.89840113  0.10159887]\n",
      " [ 0.67525902  0.32474098]\n",
      " [ 0.79447855  0.20552145]\n",
      " [ 0.87011203  0.12988797]\n",
      " [ 0.8925294   0.1074706 ]\n",
      " [ 0.6613523   0.3386477 ]\n",
      " [ 0.78404451  0.21595549]\n",
      " [ 0.86285496  0.13714504]\n",
      " [ 0.88636125  0.11363875]\n",
      " [ 0.64716123  0.35283877]\n",
      " [ 0.77323194  0.22676806]\n",
      " [ 0.85525988  0.14474012]\n",
      " [ 0.87988673  0.12011327]\n",
      " [ 0.63270575  0.36729425]\n",
      " [ 0.76204232  0.23795768]\n",
      " [ 0.8473186   0.1526814 ]\n",
      " [ 0.87309614  0.12690386]\n",
      " [ 0.6180076   0.3819924 ]\n",
      " [ 0.75047873  0.24952127]\n",
      " [ 0.83902363  0.16097637]\n",
      " [ 0.86598011  0.13401989]\n",
      " [ 0.60309025  0.39690975]\n",
      " [ 0.738546    0.261454  ]\n",
      " [ 0.83036823  0.16963177]\n",
      " [ 0.85852972  0.14147028]\n",
      " [ 0.58797874  0.41202126]\n",
      " [ 0.72625078  0.27374922]\n",
      " [ 0.82134653  0.17865347]\n",
      " [ 0.85073654  0.14926346]\n",
      " [ 0.68969848  0.31030152]\n",
      " [ 0.80514664  0.19485336]\n",
      " [ 0.87745972  0.12254028]\n",
      " [ 0.89875651  0.10124349]\n",
      " [ 0.67611352  0.32388648]\n",
      " [ 0.79511453  0.20488547]\n",
      " [ 0.87055211  0.12944789]\n",
      " [ 0.89290287  0.10709713]\n",
      " [ 0.6622251   0.3377749 ]\n",
      " [ 0.78470403  0.21529597]\n",
      " [ 0.86331576  0.13668424]\n",
      " [ 0.88675343  0.11324657]\n",
      " [ 0.64805114  0.35194886]\n",
      " [ 0.77391497  0.22608503]\n",
      " [ 0.85574193  0.14425807]\n",
      " [ 0.88029824  0.11970176]\n",
      " [ 0.63361147  0.36638853]\n",
      " [ 0.7627487   0.2372513 ]\n",
      " [ 0.84782239  0.15217761]\n",
      " [ 0.87352757  0.12647243]\n",
      " [ 0.61892774  0.38107226]\n",
      " [ 0.75120823  0.24879177]\n",
      " [ 0.83954961  0.16045039]\n",
      " [ 0.86643204  0.13356796]\n",
      " [ 0.6040233   0.3959767 ]\n",
      " [ 0.73929827  0.26070173]\n",
      " [ 0.83091679  0.16908321]\n",
      " [ 0.85900268  0.14099732]\n",
      " [ 0.5889231   0.4110769 ]\n",
      " [ 0.72702535  0.27297465]\n",
      " [ 0.82191801  0.17808199]\n",
      " [ 0.85123103  0.14876897]\n",
      " [ 0.57365351  0.42634649]\n",
      " [ 0.71439786  0.28560214]\n",
      " [ 0.81254835  0.18745165]\n",
      " [ 0.84310926  0.15689074]\n",
      " [ 0.55824219  0.44175781]\n",
      " [ 0.70142613  0.29857387]\n",
      " [ 0.80280399  0.19719601]\n",
      " [ 0.83463023  0.16536977]\n",
      " [ 0.66309679  0.33690321]\n",
      " [ 0.78536209  0.21463791]\n",
      " [ 0.86377525  0.13622475]\n",
      " [ 0.88714444  0.11285556]\n",
      " [ 0.64894002  0.35105998]\n",
      " [ 0.77459653  0.22540347]\n",
      " [ 0.85622264  0.14377736]\n",
      " [ 0.88070853  0.11929147]\n",
      " [ 0.63451626  0.36548374]\n",
      " [ 0.76345364  0.23654636]\n",
      " [ 0.84832482  0.15167518]\n",
      " [ 0.87395774  0.12604226]\n",
      " [ 0.61984703  0.38015297]\n",
      " [ 0.75193631  0.24806369]\n",
      " [ 0.8400742   0.1599258 ]\n",
      " [ 0.86688267  0.13311733]\n",
      " [ 0.6049556   0.3950444 ]\n",
      " [ 0.74004914  0.25995086]\n",
      " [ 0.83146393  0.16853607]\n",
      " [ 0.85947431  0.14052569]\n",
      " [ 0.58986681  0.41013319]\n",
      " [ 0.72779855  0.27220145]\n",
      " [ 0.82248805  0.17751195]\n",
      " [ 0.85172417  0.14827583]\n",
      " [ 0.57460695  0.42539305]\n",
      " [ 0.71519282  0.28480718]\n",
      " [ 0.81314157  0.18685843]\n",
      " [ 0.84362438  0.15637562]\n",
      " [ 0.55920361  0.44079639]\n",
      " [ 0.70224215  0.29775785]\n",
      " [ 0.80342058  0.19657942]\n",
      " [ 0.83516775  0.16483225]\n",
      " [ 0.54368545  0.45631455]\n",
      " [ 0.68895869  0.31104131]\n",
      " [ 0.79332242  0.20667758]\n",
      " [ 0.82634793  0.17365207]\n",
      " [ 0.52808202  0.47191798]\n",
      " [ 0.6753566   0.3246434 ]\n",
      " [ 0.78284573  0.21715427]\n",
      " [ 0.8171595   0.1828405 ]\n",
      " [ 0.63542009  0.36457991]\n",
      " [ 0.76415713  0.23584287]\n",
      " [ 0.84882588  0.15117412]\n",
      " [ 0.87438667  0.12561333]\n",
      " [ 0.62076546  0.37923454]\n",
      " [ 0.75266296  0.24733704]\n",
      " [ 0.8405974   0.1594026 ]\n",
      " [ 0.86733201  0.13266799]\n",
      " [ 0.60588713  0.39411287]\n",
      " [ 0.74079861  0.25920139]\n",
      " [ 0.83200967  0.16799033]\n",
      " [ 0.85994462  0.14005538]\n",
      " [ 0.59080985  0.40919015]\n",
      " [ 0.72857038  0.27142962]\n",
      " [ 0.82305667  0.17694333]\n",
      " [ 0.85221596  0.14778404]\n",
      " [ 0.57555984  0.42444016]\n",
      " [ 0.71598645  0.28401355]\n",
      " [ 0.81373334  0.18626666]\n",
      " [ 0.84413812  0.15586188]\n",
      " [ 0.56016459  0.43983541]\n",
      " [ 0.70305688  0.29694312]\n",
      " [ 0.80403572  0.19596428]\n",
      " [ 0.83570386  0.16429614]\n",
      " [ 0.54465271  0.45534729]\n",
      " [ 0.68979371  0.31020629]\n",
      " [ 0.79396106  0.20603894]\n",
      " [ 0.82690678  0.17309322]\n",
      " [ 0.5290537   0.4709463 ]\n",
      " [ 0.67621097  0.32378903]\n",
      " [ 0.78350791  0.21649209]\n",
      " [ 0.8177414   0.1822586 ]\n",
      " [ 0.51339773  0.48660227]\n",
      " [ 0.66232464  0.33767536]\n",
      " [ 0.77267627  0.22732373]\n",
      " [ 0.80820327  0.19179673]\n",
      " [ 0.49771543  0.50228457]\n",
      " [ 0.64815264  0.35184736]\n",
      " [ 0.76146768  0.23853232]\n",
      " [ 0.79828911  0.20171089]\n",
      " [ 0.60681789  0.39318211]\n",
      " [ 0.74154667  0.25845333]\n",
      " [ 0.83255399  0.16744601]\n",
      " [ 0.86041361  0.13958639]\n",
      " [ 0.59175223  0.40824777]\n",
      " [ 0.72934084  0.27065916]\n",
      " [ 0.82362385  0.17637615]\n",
      " [ 0.8527064   0.1472936 ]\n",
      " [ 0.57651216  0.42348784]\n",
      " [ 0.71677874  0.28322126]\n",
      " [ 0.81432367  0.18567633]\n",
      " [ 0.84465048  0.15534952]\n",
      " [ 0.56112512  0.43887488]\n",
      " [ 0.70387032  0.29612968]\n",
      " [ 0.80464941  0.19535059]\n",
      " [ 0.83623857  0.16376143]\n",
      " [ 0.54561964  0.45438036]\n",
      " [ 0.6906275   0.3093725 ]\n",
      " [ 0.79459823  0.20540177]\n",
      " [ 0.82746421  0.17253579]\n",
      " [ 0.53002517  0.46997483]\n",
      " [ 0.67706418  0.32293582]\n",
      " [ 0.78416862  0.21583138]\n",
      " [ 0.81832186  0.18167814]\n",
      " [ 0.51437185  0.48562815]\n",
      " [ 0.66319621  0.33680379]\n",
      " [ 0.77336047  0.22663953]\n",
      " [ 0.808807    0.191193  ]\n",
      " [ 0.49869029  0.50130971]\n",
      " [ 0.6490414   0.3509586 ]\n",
      " [ 0.76217524  0.23782476]\n",
      " [ 0.79891628  0.20108372]\n",
      " [ 0.4830113   0.5169887 ]\n",
      " [ 0.63461946  0.36538054]\n",
      " [ 0.75061599  0.24938401]\n",
      " [ 0.78864761  0.21135239]\n",
      " [ 0.4673657   0.5326343 ]\n",
      " [ 0.61995189  0.38004811]\n",
      " [ 0.73868755  0.26131245]\n",
      " [ 0.77800026  0.22199974]\n",
      " [ 0.57746392  0.42253608]\n",
      " [ 0.71756969  0.28243031]\n",
      " [ 0.81491255  0.18508745]\n",
      " [ 0.84516147  0.15483853]\n",
      " [ 0.56208519  0.43791481]\n",
      " [ 0.70468246  0.29531754]\n",
      " [ 0.80526163  0.19473837]\n",
      " [ 0.83677188  0.16322812]\n",
      " [ 0.54658622  0.45341378]\n",
      " [ 0.69146005  0.30853995]\n",
      " [ 0.79523394  0.20476606]\n",
      " [ 0.82802021  0.17197979]\n",
      " [ 0.53099641  0.46900359]\n",
      " [ 0.6779162   0.3220838 ]\n",
      " [ 0.78482786  0.21517214]\n",
      " [ 0.81890088  0.18109912]\n",
      " [ 0.51534586  0.48465414]\n",
      " [ 0.66406667  0.33593333]\n",
      " [ 0.77404322  0.22595678]\n",
      " [ 0.80940928  0.19059072]\n",
      " [ 0.49966516  0.50033484]\n",
      " [ 0.64992913  0.35007087]\n",
      " [ 0.76288135  0.23711865]\n",
      " [ 0.799542    0.200458  ]\n",
      " [ 0.48398511  0.51601489]\n",
      " [ 0.63552318  0.36447682]\n",
      " [ 0.75134523  0.24865477]\n",
      " [ 0.78929685  0.21070315]\n",
      " [ 0.46833653  0.53166347]\n",
      " [ 0.62087022  0.37912978]\n",
      " [ 0.73943955  0.26056045]\n",
      " [ 0.77867303  0.22132697]\n",
      " [ 0.45274999  0.54725001]\n",
      " [ 0.6059934   0.3940066 ]\n",
      " [ 0.72717083  0.27282917]\n",
      " [ 0.76767122  0.23232878]\n",
      " [ 0.43725556  0.56274444]\n",
      " [ 0.59091744  0.40908256]\n",
      " [ 0.71454742  0.28545258]\n",
      " [ 0.75629369  0.24370631]\n",
      " [ 0.54755245  0.45244755]\n",
      " [ 0.69229135  0.30770865]\n",
      " [ 0.79586819  0.20413181]\n",
      " [ 0.8285748   0.1714252 ]\n",
      " [ 0.53196741  0.46803259]\n",
      " [ 0.67876704  0.32123296]\n",
      " [ 0.78548565  0.21451435]\n",
      " [ 0.81947846  0.18052154]\n",
      " [ 0.51631975  0.48368025]\n",
      " [ 0.66493601  0.33506399]\n",
      " [ 0.77472451  0.22527549]\n",
      " [ 0.81001011  0.18998989]\n",
      " [ 0.50064002  0.49935998]\n",
      " [ 0.65081583  0.34918417]\n",
      " [ 0.76358602  0.23641398]\n",
      " [ 0.80016626  0.19983374]\n",
      " [ 0.48495904  0.51504096]\n",
      " [ 0.63642595  0.36357405]\n",
      " [ 0.75207304  0.24792696]\n",
      " [ 0.78994463  0.21005537]\n",
      " [ 0.46930761  0.53069239]\n",
      " [ 0.62178769  0.37821231]\n",
      " [ 0.74019016  0.25980984]\n",
      " [ 0.77934434  0.22065566]\n",
      " [ 0.45371633  0.54628367]\n",
      " [ 0.60692407  0.39307593]\n",
      " [ 0.72794377  0.27205623]\n",
      " [ 0.76836597  0.23163403]\n",
      " [ 0.43821531  0.56178469]\n",
      " [ 0.59185974  0.40814026]\n",
      " [ 0.71534213  0.28465787]\n",
      " [ 0.7570117   0.2429883 ]\n",
      " [ 0.42283396  0.57716604]\n",
      " [ 0.57662082  0.42337918]\n",
      " [ 0.70239542  0.29760458]\n",
      " [ 0.74528536  0.25471464]\n",
      " [ 0.40760079  0.59239921]\n",
      " [ 0.56123471  0.43876529]\n",
      " [ 0.68911578  0.31088422]\n",
      " [ 0.73319256  0.26680744]\n",
      " [ 0.51729352  0.48270648]\n",
      " [ 0.66580424  0.33419576]\n",
      " [ 0.77540434  0.22459566]\n",
      " [ 0.81060949  0.18939051]\n",
      " [ 0.50161489  0.49838511]\n",
      " [ 0.65170148  0.34829852]\n",
      " [ 0.76428924  0.23571076]\n",
      " [ 0.80078906  0.19921094]\n",
      " [ 0.48593308  0.51406692]\n",
      " [ 0.63732776  0.36267224]\n",
      " [ 0.75279942  0.24720058]\n",
      " [ 0.79059095  0.20940905]\n",
      " [ 0.47027892  0.52972108]\n",
      " [ 0.62270428  0.37729572]\n",
      " [ 0.74093936  0.25906064]\n",
      " [ 0.78001419  0.21998581]\n",
      " [ 0.45468302  0.54531698]\n",
      " [ 0.60785397  0.39214603]\n",
      " [ 0.72871534  0.27128466]\n",
      " [ 0.76905928  0.23094072]\n",
      " [ 0.43917552  0.56082448]\n",
      " [ 0.59280137  0.40719863]\n",
      " [ 0.71613551  0.28386449]\n",
      " [ 0.75772827  0.24227173]\n",
      " [ 0.4237859   0.5762141 ]\n",
      " [ 0.57757251  0.42242749]\n",
      " [ 0.70320991  0.29679009]\n",
      " [ 0.7460249   0.2539751 ]\n",
      " [ 0.40854271  0.59145729]\n",
      " [ 0.56219473  0.43780527]\n",
      " [ 0.68995057  0.31004943]\n",
      " [ 0.73395469  0.26604531]\n",
      " [ 0.3934734   0.6065266 ]\n",
      " [ 0.54669651  0.45330349]\n",
      " [ 0.67637148  0.32362852]\n",
      " [ 0.72152497  0.27847503]\n",
      " [ 0.37860412  0.62139588]\n",
      " [ 0.53110724  0.46889276]\n",
      " [ 0.66248859  0.33751141]\n",
      " [ 0.70874497  0.29125503]\n",
      " [ 0.48690723  0.51309277]\n",
      " [ 0.63822861  0.36177139]\n",
      " [ 0.75352436  0.24647564]\n",
      " [ 0.7912358   0.2087642 ]\n",
      " [ 0.47125046  0.52874954]\n",
      " [ 0.62362     0.37638   ]\n",
      " [ 0.74168715  0.25831285]\n",
      " [ 0.78068258  0.21931742]\n",
      " [ 0.45565005  0.54434995]\n",
      " [ 0.60878309  0.39121691]\n",
      " [ 0.72948554  0.27051446]\n",
      " [ 0.76975112  0.23024888]\n",
      " [ 0.44013619  0.55986381]\n",
      " [ 0.59374231  0.40625769]\n",
      " [ 0.71692755  0.28307245]\n",
      " [ 0.7584434   0.2415566 ]\n",
      " [ 0.4247384   0.5752616 ]\n",
      " [ 0.57852362  0.42147638]\n",
      " [ 0.70402311  0.29597689]\n",
      " [ 0.74676304  0.25323696]\n",
      " [ 0.40948529  0.59051471]\n",
      " [ 0.56315428  0.43684572]\n",
      " [ 0.69078412  0.30921588]\n",
      " [ 0.73471543  0.26528457]\n",
      " [ 0.3944044   0.6055956 ]\n",
      " [ 0.5476627   0.4523373 ]\n",
      " [ 0.67722446  0.32277554]\n",
      " [ 0.7223078   0.2776922 ]\n",
      " [ 0.37952196  0.62047804]\n",
      " [ 0.53207821  0.46792179]\n",
      " [ 0.66335995  0.33664005]\n",
      " [ 0.70954926  0.29045074]\n",
      " [ 0.36486275  0.63513725]\n",
      " [ 0.51643089  0.48356911]\n",
      " [ 0.64920838  0.35079162]\n",
      " [ 0.69645088  0.30354912]\n",
      " [ 0.35044996  0.64955004]\n",
      " [ 0.50075128  0.49924872]\n",
      " [ 0.63478944  0.36521056]\n",
      " [ 0.68302569  0.31697431]]\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression()\n",
    "model = lm.fit(train_cols,data['admit'])\n",
    "actuals = lm.predict(combos_more_new) \n",
    "probas = lm.predict_proba(combos_more_new)\n",
    "print probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The probabilities of the observations being admitted decreases for the last four observations, going from 65% chance of being admitted to 32% chance of being admitted. This is based on my understanding that the numbers in the second column of the output array represent the probability of being admitted. The probabilities of admit for the last 4 observations most likely decreases because the prestige levels gradually decrease from 1 to 4 while the gre and gpa scores stay the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
